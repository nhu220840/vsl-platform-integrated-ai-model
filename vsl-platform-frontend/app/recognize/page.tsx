"use client";

import { useState, useEffect, useCallback, useRef } from "react";
import Link from "next/link";
import { useHandTracking } from "@/hooks/useHandTracking";
import CameraView from "@/components/features/ai/CameraView";
import apiClient from "@/lib/api-client";
import { ApiResponse, GestureInputDTO } from "@/types/api";
import styles from "../../styles/recognize.module.css";

/**
 * RECOGNITION_BATCH_SIZE: Ng∆∞·ª°ng s·ªë frames ƒë·ªÉ trigger API call
 *
 * - 20 frames = ~0.67 gi√¢y ·ªü 30 FPS
 * - C√¢n b·∫±ng gi·ªØa ƒë·ªô ph·∫£n h·ªìi nhanh v√† rate limit (10 req/sec)
 * - ƒê·∫£m b·∫£o ƒë·ªß d·ªØ li·ªáu cho model AI x·ª≠ l√Ω ch√≠nh x√°c
 */
const RECOGNITION_BATCH_SIZE = 20;

export default function GestureRecognitionPage() {
  // Hook: MediaPipe HandTracking
  const {
    videoRef,
    canvasRef,
    startCapture,
    stopCapture,
    currentBatch,
    setFrameBatch,
    isReady,
    isCapturing,
  } = useHandTracking();

  // State: Recognition Results
  const [currentSentence, setCurrentSentence] = useState("");
  const [confidence, setConfidence] = useState(0);

  // State: API Processing Status
  const [isRecognizing, setIsRecognizing] = useState(false);
  const [recognitionError, setRecognitionError] = useState<string | null>(null);
  const [wordCount, setWordCount] = useState(0);
  const [gesturesPerSecond, setGesturesPerSecond] = useState(0);
  const [elapsedTime, setElapsedTime] = useState(0);

  const startTimeRef = useRef<number | null>(null);
  const timerRef = useRef<NodeJS.Timeout | null>(null);
  const gestureCountRef = useRef(0);
  const lastRecognitionTimeRef = useRef<number>(0);

  // Timer for elapsed time
  useEffect(() => {
    if (isCapturing) {
      startTimeRef.current = Date.now();
      timerRef.current = setInterval(() => {
        if (startTimeRef.current) {
          const elapsed = Math.floor(
            (Date.now() - startTimeRef.current) / 1000
          );
          setElapsedTime(elapsed);
        }
      }, 1000);
    } else {
      if (timerRef.current) {
        clearInterval(timerRef.current);
      }
      startTimeRef.current = null;
      setElapsedTime(0);
    }

    return () => {
      if (timerRef.current) {
        clearInterval(timerRef.current);
      }
    };
  }, [isCapturing]);

  /**
   * sendRecognitionBatch - G·ª≠i landmarks batch ƒë·∫øn API backend
   *
   * Flow:
   * 1. Validate: Ki·ªÉm tra batch kh√¥ng r·ªóng v√† kh√¥ng ƒëang x·ª≠ l√Ω
   * 2. Throttle: ƒê·∫£m b·∫£o delay t·ªëi thi·ªÉu gi·ªØa c√°c calls (rate limit)
   * 3. Prepare: ƒê√≥ng g√≥i GestureInputDTO v·ªõi frames v√† currentText
   * 4. API Call: POST /vsl/recognize
   * 5. Process Response: C·∫≠p nh·∫≠t sentence, stats, confidence
   * 6. Reset: X√≥a batch ƒë·ªÉ chu·∫©n b·ªã cho c·ª≠ ch·ªâ ti·∫øp theo
   * 7. Error Handling: Log v√† hi·ªÉn th·ªã th√¥ng b√°o l·ªói
   */
  const sendRecognitionBatch = useCallback(async () => {
    // Guard 1: Validate batch
    if (currentBatch.length === 0) {
      console.log("[Recognition] Batch empty, skipping");
      return;
    }

    // Guard 2: Prevent concurrent API calls
    if (isRecognizing) {
      console.log("[Recognition] Already processing, skipping");
      return;
    }

    // Guard 3: Rate limiting - ensure minimum 100ms between calls
    const now = Date.now();
    const timeSinceLastCall = now - lastRecognitionTimeRef.current;
    if (timeSinceLastCall < 100) {
      console.log(`[Recognition] Throttled, wait ${100 - timeSinceLastCall}ms`);
      return;
    }

    // Start recognition
    setIsRecognizing(true);
    setRecognitionError(null);
    lastRecognitionTimeRef.current = now;

    console.log(
      `[Recognition] Sending batch: ${currentBatch.length} frames, current text: "${currentSentence}"`
    );

    try {
      // Prepare payload: ONLY landmarks and current text, NO video stream
      const payload: GestureInputDTO = {
        frames: currentBatch,
        currentText: currentSentence || "", // Provide context for accent restoration
      };

      // API Call: POST /vsl/recognize
      const response = await apiClient.post<ApiResponse<string>>(
        "/vsl/recognize",
        payload
      );

      // Validate response
      if (response.data.code === 200 && response.data.data) {
        const newSentence = response.data.data;

        console.log(`[Recognition] Success: "${newSentence}"`);

        // Update sentence
        setCurrentSentence(newSentence);

        // Update word count
        const words = newSentence
          .trim()
          .split(/\s+/)
          .filter((w: string) => w.length > 0);
        setWordCount(words.length);

        // Update gesture count and rate
        gestureCountRef.current += 1;
        if (elapsedTime > 0) {
          const rate = gestureCountRef.current / elapsedTime;
          setGesturesPerSecond(parseFloat(rate.toFixed(1)));
        }

        // Update confidence (default 85% until backend provides actual value)
        setConfidence(85);

        // Reset batch after successful recognition
        setFrameBatch([]);
      } else {
        // API returned non-200 code or empty data
        const errorMsg =
          response.data.message || "API tr·∫£ v·ªÅ d·ªØ li·ªáu kh√¥ng h·ª£p l·ªá";
        console.error("[Recognition] API error:", errorMsg);
        setRecognitionError(errorMsg);

        // Keep batch for retry
      }
    } catch (error: unknown) {
      // Network error or API unreachable
      console.error("[Recognition] Network error:", error);

      let errorMessage = "Kh√¥ng th·ªÉ k·∫øt n·ªëi ƒë·∫øn server";
      if (error instanceof Error) {
        errorMessage = error.message;
      }

      setRecognitionError(errorMessage);

      // Don't reset batch - will retry on next cycle
      console.log("[Recognition] Keeping batch for retry");
    } finally {
      setIsRecognizing(false);
    }
  }, [
    currentBatch,
    currentSentence,
    elapsedTime,
    isRecognizing,
    setFrameBatch,
  ]);

  /**
   * Batch Monitor - T·ª± ƒë·ªông trigger API khi ƒë·ªß frames
   *
   * ƒêi·ªÅu ki·ªán:
   * - currentBatch.length >= RECOGNITION_BATCH_SIZE (20 frames)
   * - !isRecognizing (kh√¥ng ƒëang x·ª≠ l√Ω API call kh√°c)
   *
   * Note: sendRecognitionBatch c√≥ guard ri√™ng ƒë·ªÉ prevent concurrent calls
   */
  useEffect(() => {
    if (currentBatch.length >= RECOGNITION_BATCH_SIZE && !isRecognizing) {
      console.log(
        `[Recognition] Batch threshold reached: ${currentBatch.length}/${RECOGNITION_BATCH_SIZE}`
      );
      sendRecognitionBatch();
    }
  }, [currentBatch, isRecognizing, sendRecognitionBatch]);

  // Handle start/stop recording
  const toggleRecording = () => {
    if (isCapturing) {
      stopCapture();
      gestureCountRef.current = 0;
      setGesturesPerSecond(0);
    } else {
      startCapture();
    }
  };

  // Clear text
  const clearText = () => {
    setCurrentSentence("");
    setWordCount(0);
    gestureCountRef.current = 0;
    setGesturesPerSecond(0);
  };

  // Format elapsed time as MM:SS
  const formatTime = (seconds: number) => {
    const mins = Math.floor(seconds / 60);
    const secs = seconds % 60;
    return `${mins.toString().padStart(2, "0")}:${secs
      .toString()
      .padStart(2, "0")}`;
  };

  return (
    <div className={styles["hud-container"]}>
      <div className={styles.scanline} />

      {/* Status Bar */}
      <div className={styles["status-bar"]}>
        <div className={styles["status-left"]}>
          <div className={styles["status-item"]}>
            <div className={styles["status-indicator"]} />
            <span>SYSTEM ONLINE</span>
          </div>
          <div className={styles["status-item"]}>
            <span>FPS: 30</span>
          </div>
          <div className={styles["status-item"]}>
            <span>MODEL: MLP v2.1</span>
          </div>
        </div>
        <div className={styles["status-right"]}>
          <Link
            href="/"
            style={{
              color: "#00ff41",
              textDecoration: "none",
              letterSpacing: "2px",
              fontSize: "12px",
            }}
          >
            ‚Üê THO√ÅT
          </Link>
        </div>
      </div>

      {/* Main Content */}
      <div className={styles["main-content"]}>
        {/* Sidebar */}
        <div className={styles.sidebar}>
          <div className={styles["sidebar-title"]}>K·∫æT QU·∫¢ NH·∫¨N D·∫†NG</div>

          <div className={styles["output-text"]}>
            {currentSentence || "B·∫Øt ƒë·∫ßu ghi ƒë·ªÉ nh·∫≠n d·∫°ng c·ª≠ ch·ªâ..."}
            {isRecognizing && (
              <span style={{ color: "#FFD700", marginLeft: "10px" }}>
                ‚è≥ ƒêang x·ª≠ l√Ω...
              </span>
            )}
          </div>

          {/* Error Display */}
          {recognitionError && (
            <div
              style={{
                color: "#ff4444",
                fontSize: "14px",
                marginTop: "10px",
                padding: "10px",
                background: "rgba(255, 68, 68, 0.1)",
                borderRadius: "4px",
                border: "1px solid #ff4444",
              }}
            >
              ‚ö†Ô∏è {recognitionError}
            </div>
          )}

          <div className={styles["confidence-meter"]}>
            <div className={styles["meter-label"]}>
              <span>ƒê·ªò TIN C·∫¨Y</span>
              <span>{confidence}%</span>
            </div>
            <div className={styles["meter-bar"]}>
              <div
                className={styles["meter-fill"]}
                style={{ width: `${confidence}%` }}
              />
            </div>
          </div>

          <div className={styles["control-buttons"]}>
            <button
              className={`${styles.btn} ${
                isCapturing ? styles["btn-danger"] : styles["btn-primary"]
              }`}
              onClick={toggleRecording}
              disabled={!isReady}
            >
              {isCapturing ? "‚èπ D·ª´ng ghi" : "‚è∫ B·∫Øt ƒë·∫ßu ghi"}
            </button>
            <button className={styles.btn} onClick={clearText}>
              üóë X√≥a vƒÉn b·∫£n
            </button>
            <button
              className={styles.btn}
              onClick={() => {
                if (currentSentence) {
                  navigator.clipboard.writeText(currentSentence);
                }
              }}
            >
              üìã Sao ch√©p
            </button>
          </div>
        </div>

        {/* Viewport */}
        <div className={styles["viewport-container"]}>
          <div className={styles["viewport-wrapper"]}>
            {/* CameraView Component - handles video + canvas rendering */}
            <CameraView
              videoRef={videoRef}
              canvasRef={canvasRef}
              isCapturing={isCapturing}
              isReady={isReady}
            />
            <div className={styles["tracking-overlay"]} />
          </div>

          {/* Stats Grid */}
          <div className={styles["stats-grid"]}>
            <div className={styles["stat-card"]}>
              <div className={styles["stat-label"]}>T·ªïng t·ª´</div>
              <div className={styles["stat-value"]}>{wordCount}</div>
            </div>
            <div className={styles["stat-card"]}>
              <div className={styles["stat-label"]}>C·ª≠ ch·ªâ/gi√¢y</div>
              <div className={styles["stat-value"]}>{gesturesPerSecond}</div>
            </div>
            <div className={styles["stat-card"]}>
              <div className={styles["stat-label"]}>Th·ªùi gian</div>
              <div className={styles["stat-value"]}>
                {formatTime(elapsedTime)}
              </div>
            </div>
            <div className={styles["stat-card"]}>
              <div className={styles["stat-label"]}>Tr·∫°ng th√°i</div>
              <div
                className={styles["stat-value"]}
                style={{ fontSize: "16px" }}
              >
                {isCapturing
                  ? isRecognizing
                    ? "X·ª¨ L√ù"
                    : "ƒêANG GHI"
                  : "CH∆ØA B·∫ÆT ƒê·∫¶U"}
              </div>
            </div>
            <div className={styles["stat-card"]}>
              <div className={styles["stat-label"]}>Batch</div>
              <div className={styles["stat-value"]}>
                {currentBatch.length}/{RECOGNITION_BATCH_SIZE}
              </div>
            </div>
          </div>
        </div>
      </div>
    </div>
  );
}
